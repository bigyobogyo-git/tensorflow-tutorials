{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b97aa8a-4186-4fe2-ba9e-b1baa1114e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 16:21:08.098514: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764256868.110199   32570 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764256868.113821   32570 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764256868.123989   32570 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764256868.123999   32570 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764256868.124001   32570 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764256868.124002   32570 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-27 16:21:08.127080: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/xy/Desktop/ml/TF/tf_2.19.1/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.12) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "867de806-8ba3-4e9e-9c3d-64f74ce72826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate multiple CPUs with virtual devices\n",
    "N_VIRTUAL_DEVICES = 2\n",
    "physical_devices = tf.config.list_physical_devices(\"CPU\")\n",
    "tf.config.set_logical_device_configuration(\n",
    "    physical_devices[0], [tf.config.LogicalDeviceConfiguration() for _ in range(N_VIRTUAL_DEVICES)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d49580f-59a0-4a26-8a6b-4a27d1f5548a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices:\n",
      "0) LogicalDevice(name='/device:CPU:0', device_type='CPU')\n",
      "1) LogicalDevice(name='/device:CPU:1', device_type='CPU')\n",
      "2) LogicalDevice(name='/device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764256870.250585   32570 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8844 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Available devices:\")\n",
    "for i, device in enumerate(tf.config.list_logical_devices()):\n",
    "  print(\"%d) %s\" % (i, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c30a26b1-195e-42be-a20b-b9cf5b000e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(4, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 16:21:10.419478: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "global_batch_size = 16\n",
    "# Create a tf.data.Dataset object.\n",
    "dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(global_batch_size)\n",
    "\n",
    "@tf.function\n",
    "def train_step(inputs):\n",
    "  features, labels = inputs\n",
    "  return labels - 0.3 * features\n",
    "\n",
    "# Iterate over the dataset using the for..in construct.\n",
    "for inputs in dataset:\n",
    "  print(train_step(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96a61295-e754-4e21-a9ee-70673c0f5e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "(<tf.Tensor: shape=(16, 1), dtype=float32, numpy=\n",
      "array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]], dtype=float32)>, <tf.Tensor: shape=(16, 1), dtype=float32, numpy=\n",
      "array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "global_batch_size = 16\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(global_batch_size)\n",
    "# Distribute input using the `experimental_distribute_dataset`.\n",
    "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n",
    "# 1 global batch of data fed to the model in 1 step.\n",
    "print(next(iter(dist_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd57a32c-f460-444b-88fa-5c7c107e44bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(64).batch(16)\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "dataset = dataset.with_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4e6514e-7c35-4b81-a525-d191481e5959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "def dataset_fn(input_context):\n",
    "  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n",
    "  dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(64).batch(16)\n",
    "  dataset = dataset.shard(\n",
    "      input_context.num_input_pipelines, input_context.input_pipeline_id)\n",
    "  dataset = dataset.batch(batch_size)\n",
    "  dataset = dataset.prefetch(2)  # This prefetches 2 batches per device.\n",
    "  return dataset\n",
    "\n",
    "dist_dataset = mirrored_strategy.distribute_datasets_from_function(dataset_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c1b82d4-32e0-4801-a2f6-7b38b1344b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(4, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 16:21:10.566993: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "2025-11-27 16:21:10.576035: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "global_batch_size = 16\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(global_batch_size)\n",
    "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "@tf.function\n",
    "def train_step(inputs):\n",
    "  features, labels = inputs\n",
    "  return labels - 0.3 * features\n",
    "\n",
    "for x in dist_dataset:\n",
    "  # train_step trains the model using the dataset elements\n",
    "  loss = mirrored_strategy.run(train_step, args=(x,))\n",
    "  print(\"Loss is \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93dcdcb9-7e0d-44a2-a328-e13d0d666c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n",
      "Loss is  tf.Tensor(\n",
      "[[0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]\n",
      " [0.7]], shape=(16, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "steps_per_epoch = 5\n",
    "for epoch in range(num_epochs):\n",
    "  dist_iterator = iter(dist_dataset)\n",
    "  for step in range(steps_per_epoch):\n",
    "    # train_step trains the model using the dataset elements\n",
    "    loss = mirrored_strategy.run(train_step, args=(next(dist_iterator),))\n",
    "    # which is the same as\n",
    "    # loss = mirrored_strategy.run(train_step, args=(dist_iterator.get_next(),))\n",
    "    print(\"Loss is \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29ed4386-43cf-4911-a28b-1056abd079de",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_fn(iterator):\n",
    "  for _ in tf.range(steps_per_loop):\n",
    "    strategy.run(step_fn, args=(next(iterator),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ce41b17-7617-4552-a8c3-0faa71d2dd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "([0 1 2 3],)\n",
      "([4 5 6 7],)\n",
      "([8],)\n"
     ]
    }
   ],
   "source": [
    "# You can break the loop with `get_next_as_optional` by checking if the `Optional` contains a value\n",
    "global_batch_size = 4\n",
    "steps_per_loop = 5\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "dataset = tf.data.Dataset.range(9).batch(global_batch_size)\n",
    "distributed_iterator = iter(strategy.experimental_distribute_dataset(dataset))\n",
    "\n",
    "@tf.function\n",
    "def train_fn(distributed_iterator):\n",
    "  for _ in tf.range(steps_per_loop):\n",
    "    optional_data = distributed_iterator.get_next_as_optional()\n",
    "    if not optional_data.has_value():\n",
    "      break\n",
    "    per_replica_results = strategy.run(lambda x: x, args=(optional_data.get_value(),))\n",
    "    tf.print(strategy.experimental_local_results(per_replica_results))\n",
    "train_fn(distributed_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e56f9dca-d77e-4661-b232-59f5e2bd0fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n",
      "([[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]], [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]])\n"
     ]
    }
   ],
   "source": [
    "global_batch_size = 16\n",
    "epochs = 5\n",
    "steps_per_epoch = 5\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(100).batch(global_batch_size)\n",
    "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "@tf.function(input_signature=[dist_dataset.element_spec])\n",
    "def train_step(per_replica_inputs):\n",
    "  def step_fn(inputs):\n",
    "    return 2 * inputs\n",
    "\n",
    "  return mirrored_strategy.run(step_fn, args=(per_replica_inputs,))\n",
    "\n",
    "for _ in range(epochs):\n",
    "  iterator = iter(dist_dataset)\n",
    "  for _ in range(steps_per_epoch):\n",
    "    output = train_step(next(iterator))\n",
    "    tf.print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fc0f2bc-fcec-40ad-9986-c68097524c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "tf.Tensor([1 3 0 1], shape=(4,), dtype=int64)\n",
      "tf.Tensor([3 0 1 3], shape=(4,), dtype=int64)\n",
      "tf.Tensor([0 1 3 0], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "vocab = [\"a\", \"b\", \"c\", \"d\", \"f\"]\n",
    "\n",
    "with strategy.scope():\n",
    "  # Create the layer(s) under scope.\n",
    "  layer = tf.keras.layers.StringLookup(vocabulary=vocab)\n",
    "\n",
    "def dataset_fn(input_context):\n",
    "  # a tf.data.Dataset\n",
    "  dataset = tf.data.Dataset.from_tensor_slices([\"a\", \"c\", \"e\"]).repeat()\n",
    "\n",
    "  # Custom your batching, sharding, prefetching, etc.\n",
    "  global_batch_size = 4\n",
    "  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n",
    "  dataset = dataset.batch(batch_size)\n",
    "  dataset = dataset.shard(\n",
    "      input_context.num_input_pipelines,\n",
    "      input_context.input_pipeline_id)\n",
    "\n",
    "  # Apply the preprocessing layer(s) to the tf.data.Dataset\n",
    "  def preprocess_with_kpl(input):\n",
    "    return layer(input)\n",
    "\n",
    "  processed_ds = dataset.map(preprocess_with_kpl)\n",
    "  return processed_ds\n",
    "\n",
    "distributed_dataset = strategy.distribute_datasets_from_function(dataset_fn)\n",
    "\n",
    "# Print out a few example batches.\n",
    "distributed_dataset_iterator = iter(distributed_dataset)\n",
    "for _ in range(3):\n",
    "  print(next(distributed_dataset_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e2d412-155b-4c12-8971-994329c254cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b488ca-4f6b-4f1d-b795-3a4b10c1624f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21643d63-3716-4e91-b7e3-65a71e13cd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "{np.int64(0): np.int64(0), np.int64(1): np.int64(2), np.int64(2): np.int64(4), np.int64(3): np.int64(6), np.int64(4): np.int64(8), np.int64(5): np.int64(10), np.int64(6): np.int64(12), np.int64(7): np.int64(14), np.int64(8): np.int64(16), np.int64(9): np.int64(18), np.int64(10): np.int64(20), np.int64(11): np.int64(22), np.int64(12): np.int64(24), np.int64(13): np.int64(26), np.int64(14): np.int64(28), np.int64(15): np.int64(30), np.int64(16): np.int64(32), np.int64(17): np.int64(34), np.int64(18): np.int64(36), np.int64(19): np.int64(38), np.int64(20): np.int64(40), np.int64(21): np.int64(42), np.int64(22): np.int64(44), np.int64(23): np.int64(46)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 16:21:11.538783: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
      "\t [[RemoteCall]]\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "dataset_size = 24\n",
    "batch_size = 6\n",
    "dataset = tf.data.Dataset.range(dataset_size).enumerate().batch(batch_size)\n",
    "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "def predict(index, inputs):\n",
    "  outputs = 2 * inputs\n",
    "  return index, outputs\n",
    "\n",
    "result = {}\n",
    "for index, inputs in dist_dataset:\n",
    "  output_index, outputs = mirrored_strategy.run(predict, args=(index, inputs))\n",
    "  indices = list(mirrored_strategy.experimental_local_results(output_index))\n",
    "  rindices = []\n",
    "  for a in indices:\n",
    "    rindices.extend(a.numpy())\n",
    "  outputs = list(mirrored_strategy.experimental_local_results(outputs))\n",
    "  routputs = []\n",
    "  for a in outputs:\n",
    "    routputs.extend(a.numpy())\n",
    "  for i, value in zip(rindices, routputs):\n",
    "    result[i] = value\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22135cb0-4a36-4843-bea6-a53c7b421182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "def value_fn(ctx):\n",
    "  return tf.constant(ctx.replica_id_in_sync_group)\n",
    "\n",
    "distributed_values = mirrored_strategy.experimental_distribute_values_from_function(value_fn)\n",
    "for _ in range(4):\n",
    "  result = mirrored_strategy.run(lambda x: x, args=(distributed_values,))\n",
    "  print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6027dbd-8983-4fa1-ac81-e3decbab62eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "tf.Tensor([0.09710831 0.5703204  0.89259994 0.09288073], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.802099   0.3934971  0.23020992 0.32965848], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.33561757 0.7681463  0.10545261 0.42162818], shape=(4,), dtype=float32)\n",
      "tf.Tensor([0.76972544 0.8378676  0.9546958  0.53708273], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "def input_gen():\n",
    "  while True:\n",
    "    yield np.random.rand(4)\n",
    "\n",
    "# use Dataset.from_generator\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    input_gen, output_types=(tf.float32), output_shapes=tf.TensorShape([4]))\n",
    "dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)\n",
    "iterator = iter(dist_dataset)\n",
    "for _ in range(4):\n",
    "  result = mirrored_strategy.run(lambda x: x, args=(next(iterator),))\n",
    "  print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd01485e-6158-434b-a033-c1cfa315b698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbef223d-015d-4107-8af5-a71e45d4d75e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7c2e5d-7cd8-4512-b730-b14a8f95f322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba1ac1a-b879-4657-b979-d97b4183c02a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fac486-69e0-4a7f-9fb1-8d8c49863595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d58407-8d54-4142-97e5-f385371f8093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56656ed-8257-4529-ba25-0d25a2716c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d240e2c-426f-4971-a253-015c9507acfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23555997-4e82-4147-bddb-77aae85978f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78eca54-dc8f-44bd-90f7-77fbb4c3e79e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71511011-e453-44be-9cca-e5617ac37f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab5910e-fb94-4b78-ad6e-b5c2f0b0f79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce17071-85c5-402c-a15d-8bd7664887fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26491fa1-421b-494c-91f2-5e2ce2074b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096c84b-7bbb-4d40-8a64-f8f71acc6f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07bc516-133b-4bf4-a076-c328f046985c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
