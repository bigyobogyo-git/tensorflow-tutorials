{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0444cc6a-7eeb-47fb-9977-1a4a53586150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 15:01:54.527535: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-27 15:01:54.527561: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-27 15:01:54.528556: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-27 15:01:54.533642: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/xy/Desktop/ml/TF/legacy/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.12) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "2025-11-27 15:01:55.095641: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.experimental import dtensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2e6449c-a782-48aa-8b98-9036a10fce2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 15:01:55.875133: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-27 15:01:55.909304: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-27 15:01:55.910989: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-27 15:01:55.913681: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-27 15:01:55.915567: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-27 15:01:55.917170: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-27 15:01:56.053779: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-27 15:01:56.054682: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-27 15:01:56.055489: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-27 15:01:56.056263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8797 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "def configure_virtual_cpus(ncpu):\n",
    "  phy_devices = tf.config.list_physical_devices('CPU')\n",
    "  tf.config.set_logical_device_configuration(\n",
    "        phy_devices[0], \n",
    "        [tf.config.LogicalDeviceConfiguration()] * ncpu)\n",
    "\n",
    "configure_virtual_cpus(8)\n",
    "tf.config.list_logical_devices('CPU')\n",
    "\n",
    "devices = [f'CPU:{i}' for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61453a9f-a77f-4332-a30b-703a4ada3946",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.experimental.enable_tf_random_generator()\n",
    "tf.keras.utils.set_random_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd6c248-d378-415d-9c99-1915d22ce311",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = dtensor.create_mesh([(\"batch\", 8)], devices=devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d67bfd-e73e-44df-8e61-9fb616c3e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_weight_layout = dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED], mesh)  # or\n",
    "example_weight_layout = dtensor.Layout.replicated(mesh, rank=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9ae553c-f7c7-4a3e-ad8c-39ef69502b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data_layout = dtensor.Layout(['batch', dtensor.UNSHARDED], mesh)  # or\n",
    "example_data_layout = dtensor.Layout.batch_sharded(mesh, 'batch', rank=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cecd1dc2-9df7-46bd-be7a-97c722d2c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsharded_layout_2d = dtensor.Layout.replicated(mesh, 2)\n",
    "unsharded_layout_1d = dtensor.Layout.replicated(mesh, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "211dfa46-323c-4756-8f7b-1d407490fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, \n",
    "                        activation='relu',\n",
    "                        name='d1',\n",
    "                        kernel_layout=unsharded_layout_2d, \n",
    "                        bias_layout=unsharded_layout_1d),\n",
    "  tf.keras.layers.Dense(10,\n",
    "                        name='d2',\n",
    "                        kernel_layout=unsharded_layout_2d, \n",
    "                        bias_layout=unsharded_layout_1d)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85b18348-66db-4be4-804e-85107e7467d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight name: d1/kernel:0 with layout: Layout.from_string(sharding_specs:unsharded,unsharded, mesh:|batch=8|0,1,2,3,4,5,6,7|0,1,2,3,4,5,6,7|/job:localhost/replica:0/task:0/device:CPU:0,/job:localhost/replica:0/task:0/device:CPU:1,/job:localhost/replica:0/task:0/device:CPU:2,/job:localhost/replica:0/task:0/device:CPU:3,/job:localhost/replica:0/task:0/device:CPU:4,/job:localhost/replica:0/task:0/device:CPU:5,/job:localhost/replica:0/task:0/device:CPU:6,/job:localhost/replica:0/task:0/device:CPU:7)\n"
     ]
    }
   ],
   "source": [
    "for weight in model.weights:\n",
    "  print(f'Weight name: {weight.name} with layout: {weight.layout}')\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c58410-7597-4e2c-8916-184cc60bf6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d360533-6966-4f7c-9c09-6a1c9b7e272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18069f11-6038-4f6e-a536-fcc76d06e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(batch_size)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38c4af21-972a-4f8f-9696-5ea4a4dc5993",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(batch_size)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e5887b2-ba0a-4f25-84b8-8b9e1c491994",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, x, y, optimizer, metrics):\n",
    "  with tf.GradientTape() as tape:\n",
    "    logits = model(x, training=True)\n",
    "    # tf.reduce_sum sums the batch sharded per-example loss to a replicated\n",
    "    # global loss (scalar).\n",
    "    loss = tf.reduce_sum(tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        y, logits, from_logits=True))\n",
    "\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  for metric in metrics.values():\n",
    "    metric.update_state(y_true=y, y_pred=logits)\n",
    "\n",
    "  loss_per_sample = loss / len(x)\n",
    "  results = {'loss': loss_per_sample}\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2db6a271-e975-470f-aa0e-11f570dfa2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def eval_step(model, x, y, metrics):\n",
    "  logits = model(x, training=False)\n",
    "  loss = tf.reduce_sum(tf.keras.losses.sparse_categorical_crossentropy(\n",
    "        y, logits, from_logits=True))\n",
    "\n",
    "  for metric in metrics.values():\n",
    "    metric.update_state(y_true=y, y_pred=logits)\n",
    "\n",
    "  loss_per_sample = loss / len(x)\n",
    "  results = {'eval_loss': loss_per_sample}\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "182f01df-0db6-4a71-9549-931865576f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_dtensor_inputs(images, labels, image_layout, label_layout):\n",
    "  num_local_devices = image_layout.mesh.num_local_devices()\n",
    "  images = tf.split(images, num_local_devices)\n",
    "  labels = tf.split(labels, num_local_devices)\n",
    "  images = dtensor.pack(images, image_layout)\n",
    "  labels = dtensor.pack(labels, label_layout)\n",
    "  return  images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a72e92bd-8080-4b69-868b-4f9b3af227d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.dtensor.experimental.optimizers.Adam(0.01, mesh=mesh)\n",
    "metrics = {'accuracy': tf.keras.metrics.SparseCategoricalAccuracy(mesh=mesh)}\n",
    "eval_metrics = {'eval_accuracy': tf.keras.metrics.SparseCategoricalAccuracy(mesh=mesh)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "973aca47-5f25-4038-952c-2cd6aad31fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 15:03:41.402384: I tensorflow/dtensor/cc/dtensor_device.cc:1626] DTensor cache key lookup missed for __inference_train_step_621. DTensor is (re-)computing its SPMD transformation.\n",
      "2025-11-27 15:03:41.418281: I tensorflow/dtensor/cc/dtensor_device.cc:1699] DTensor cache key lookup missed for __inference_train_step_621. DTensor is (re-)computing its ExecutionFunctions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    469/Unknown - 3s 6ms/step - loss: 0.2907 - accuracy: 0.8308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 15:03:43.507663: I tensorflow/dtensor/cc/dtensor_device.cc:1626] DTensor cache key lookup missed for __inference_train_step_16294. DTensor is (re-)computing its SPMD transformation.\n",
      "2025-11-27 15:03:43.518191: I tensorflow/dtensor/cc/dtensor_device.cc:1699] DTensor cache key lookup missed for __inference_train_step_16294. DTensor is (re-)computing its ExecutionFunctions.\n",
      "2025-11-27 15:03:43.723260: I tensorflow/dtensor/cc/dtensor_device.cc:1626] DTensor cache key lookup missed for __inference_eval_step_16390. DTensor is (re-)computing its SPMD transformation.\n",
      "2025-11-27 15:03:43.726239: I tensorflow/dtensor/cc/dtensor_device.cc:1699] DTensor cache key lookup missed for __inference_eval_step_16390. DTensor is (re-)computing its ExecutionFunctions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.12670570611953735\n",
      "accuracy: 0.9109166860580444\n",
      "eval_loss: 0.04795415699481964\n",
      "eval_accuracy: 0.958899974822998\n",
      "============================\n",
      "Epoch:  1\n",
      "     25/Unknown - 0s 6ms/step - loss: 0.1295 - accuracy: 0.9632"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-27 15:03:43.936336: I tensorflow/dtensor/cc/dtensor_device.cc:1626] DTensor cache key lookup missed for __inference_eval_step_18226. DTensor is (re-)computing its SPMD transformation.\n",
      "2025-11-27 15:03:43.939270: I tensorflow/dtensor/cc/dtensor_device.cc:1699] DTensor cache key lookup missed for __inference_eval_step_18226. DTensor is (re-)computing its ExecutionFunctions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    469/Unknown - 2s 4ms/step - loss: 0.1285 - accuracy: 0.9595\n",
      "loss: 0.08036476373672485\n",
      "accuracy: 0.9599999785423279\n",
      "eval_loss: 0.008920179679989815\n",
      "eval_accuracy: 0.9642000198364258\n",
      "============================\n",
      "Epoch:  2\n",
      "    469/Unknown - 2s 4ms/step - loss: 0.1010 - accuracy: 0.9682\n",
      "loss: 0.044021397829055786\n",
      "accuracy: 0.9682833552360535\n",
      "eval_loss: 0.05413995310664177\n",
      "eval_accuracy: 0.9656000137329102\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "image_layout = dtensor.Layout.batch_sharded(mesh, 'batch', rank=4)\n",
    "label_layout = dtensor.Layout.batch_sharded(mesh, 'batch', rank=1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  print(\"============================\") \n",
    "  print(\"Epoch: \", epoch)\n",
    "  for metric in metrics.values():\n",
    "    metric.reset_state()\n",
    "  step = 0\n",
    "  results = {}\n",
    "  pbar = tf.keras.utils.Progbar(target=None, stateful_metrics=[])\n",
    "  for input in ds_train:\n",
    "    images, labels = input[0], input[1]\n",
    "    images, labels = pack_dtensor_inputs(\n",
    "        images, labels, image_layout, label_layout)\n",
    "\n",
    "    results.update(train_step(model, images, labels, optimizer, metrics))\n",
    "    for metric_name, metric in metrics.items():\n",
    "      results[metric_name] = metric.result()\n",
    "\n",
    "    pbar.update(step, values=results.items(), finalize=False)\n",
    "    step += 1\n",
    "  pbar.update(step, values=results.items(), finalize=True)\n",
    "\n",
    "  for metric in eval_metrics.values():\n",
    "    metric.reset_state()\n",
    "  for input in ds_test:\n",
    "    images, labels = input[0], input[1]\n",
    "    images, labels = pack_dtensor_inputs(\n",
    "        images, labels, image_layout, label_layout)\n",
    "    results.update(eval_step(model, images, labels, eval_metrics))\n",
    "\n",
    "  for metric_name, metric in eval_metrics.items():\n",
    "    results[metric_name] = metric.result()\n",
    "\n",
    "  for metric_name, metric in results.items():\n",
    "    print(f\"{metric_name}: {metric.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63f17204-b9d2-4aac-8f0f-db2fcd03900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubclassedModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, name=None):\n",
    "    super().__init__(name=name)\n",
    "    self.feature = tf.keras.layers.Dense(16)\n",
    "    self.feature_2 = tf.keras.layers.Dense(24)\n",
    "    self.dropout = tf.keras.layers.Dropout(0.1)\n",
    "\n",
    "  def call(self, inputs, training=None):\n",
    "    x = self.feature(inputs)\n",
    "    x = self.dropout(x, training=training)\n",
    "    return self.feature_2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31efbcd0-1f70-42e5-8c92-35621f850507",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_map = tf.keras.dtensor.experimental.LayoutMap(mesh=mesh)\n",
    "\n",
    "layout_map['feature.*kernel'] = dtensor.Layout.batch_sharded(mesh, 'batch', rank=2)\n",
    "layout_map['feature.*bias'] = dtensor.Layout.batch_sharded(mesh, 'batch', rank=1)\n",
    "\n",
    "with layout_map.scope():\n",
    "  subclassed_model = SubclassedModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60f5315e-051c-4361-ac19-2c75f4771e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layout.from_string(sharding_specs:batch,unsharded, mesh:|batch=8|0,1,2,3,4,5,6,7|0,1,2,3,4,5,6,7|/job:localhost/replica:0/task:0/device:CPU:0,/job:localhost/replica:0/task:0/device:CPU:1,/job:localhost/replica:0/task:0/device:CPU:2,/job:localhost/replica:0/task:0/device:CPU:3,/job:localhost/replica:0/task:0/device:CPU:4,/job:localhost/replica:0/task:0/device:CPU:5,/job:localhost/replica:0/task:0/device:CPU:6,/job:localhost/replica:0/task:0/device:CPU:7)\n"
     ]
    }
   ],
   "source": [
    "dtensor_input = dtensor.copy_to_mesh(tf.zeros((16, 16)), layout=unsharded_layout_2d)\n",
    "# Trigger the weights creation for subclass model\n",
    "subclassed_model(dtensor_input)\n",
    "\n",
    "print(subclassed_model.feature.kernel.layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa04a3b8-4fb7-4ef2-8c83-b5e5f620dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_map = tf.keras.dtensor.experimental.LayoutMap(mesh=mesh)\n",
    "\n",
    "layout_map['feature.*kernel'] = dtensor.Layout.batch_sharded(mesh, 'batch', rank=2)\n",
    "layout_map['feature.*bias'] = dtensor.Layout.batch_sharded(mesh, 'batch', rank=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5f53175-25c6-478a-8aeb-349ade38c572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layout.from_string(sharding_specs:batch,unsharded, mesh:|batch=8|0,1,2,3,4,5,6,7|0,1,2,3,4,5,6,7|/job:localhost/replica:0/task:0/device:CPU:0,/job:localhost/replica:0/task:0/device:CPU:1,/job:localhost/replica:0/task:0/device:CPU:2,/job:localhost/replica:0/task:0/device:CPU:3,/job:localhost/replica:0/task:0/device:CPU:4,/job:localhost/replica:0/task:0/device:CPU:5,/job:localhost/replica:0/task:0/device:CPU:6,/job:localhost/replica:0/task:0/device:CPU:7)\n"
     ]
    }
   ],
   "source": [
    "with layout_map.scope():\n",
    "  inputs = tf.keras.Input((16,), batch_size=16)\n",
    "  x = tf.keras.layers.Dense(16, name='feature')(inputs)\n",
    "  x = tf.keras.layers.Dropout(0.1)(x)\n",
    "  output = tf.keras.layers.Dense(32, name='feature_2')(x)\n",
    "  model = tf.keras.Model(inputs, output)\n",
    "\n",
    "print(model.layers[1].kernel.layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e22d6130-7bf9-4f42-a127-3ce5baa94830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layout.from_string(sharding_specs:batch,unsharded, mesh:|batch=8|0,1,2,3,4,5,6,7|0,1,2,3,4,5,6,7|/job:localhost/replica:0/task:0/device:CPU:0,/job:localhost/replica:0/task:0/device:CPU:1,/job:localhost/replica:0/task:0/device:CPU:2,/job:localhost/replica:0/task:0/device:CPU:3,/job:localhost/replica:0/task:0/device:CPU:4,/job:localhost/replica:0/task:0/device:CPU:5,/job:localhost/replica:0/task:0/device:CPU:6,/job:localhost/replica:0/task:0/device:CPU:7)\n"
     ]
    }
   ],
   "source": [
    "with layout_map.scope():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(16, name='feature', input_shape=(16,)),\n",
    "      tf.keras.layers.Dropout(0.1),\n",
    "      tf.keras.layers.Dense(32, name='feature_2')\n",
    "  ])\n",
    "\n",
    "print(model.layers[2].kernel.layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f385441c-175a-4581-939d-55cdf5e7157a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae53b2d-e0ff-4e88-9517-fe169c8cd2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e982b7dd-2af3-4071-a060-7509889bbaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c467d3f5-e352-42ea-ba2b-eb335093a148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e174d31d-70e1-4219-91d6-9dc0fe73ad89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790a842-708c-40ae-9645-68c4f27172c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffecaade-4ca2-415b-86f8-937112f3edef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b37784-c27e-4c38-bf37-f8f4b0dca464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1a023c-1e00-45ea-9154-367812c5f883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
